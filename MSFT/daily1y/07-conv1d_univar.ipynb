{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Одномерная модель на 1D свёрточных слоях*\n",
    "\n",
    "В качестве единственного признака используется сама цена."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import datetime\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_datareader import data as pdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# tf.test.is_gpu_available()\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import (Input, Dense, Convolution1D, MaxPooling1D, Flatten,\n",
    "                                     ReLU, LeakyReLU, Dropout, BatchNormalization)\n",
    "from tensorflow.keras.regularizers import L1L2\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping, LearningRateScheduler\n",
    "from tensorflow.keras.optimizers import Nadam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mdp import TimeSeries\n",
    "from mdp import MarketData\n",
    "from mdp import MovingWindowFeatures\n",
    "from mdp import ClassificationGenerator, RegressionGenerator, MultitaskGenerator\n",
    "from mdp import invert_log_ret\n",
    "\n",
    "import mdp.utils as utils\n",
    "import mdp.plotHelpers as plotHelpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "import mdp\n",
    "\n",
    "importlib.reload(mdp)\n",
    "importlib.reload(mdp.datasetGenerator)\n",
    "importlib.reload(mdp.marketData)\n",
    "importlib.reload(mdp.movingWindowFeatures)\n",
    "importlib.reload(mdp.timeSeries)\n",
    "importlib.reload(mdp.plotHelpers)\n",
    "importlib.reload(mdp.utils);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Параметры*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INSTRUMENT = 'MSFT' # Microsoft corp\n",
    "START_FROM = '2018-11-14'\n",
    "END_DATE = '2020-01-01'\n",
    "WINDOW_SIZE = 10\n",
    "FORECAST_OFFSET=1\n",
    "BATCH_SIZE = 8\n",
    "VAL_SPLIT = '2019-11-01'\n",
    "TEST_SPLIT = '2019-12-01'\n",
    "FORCE_TRAIN = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Исходные данные*\n",
    "\n",
    "Загрузка данных и вычисление индикаторов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instr = MarketData.create_from_tiingo(INSTRUMENT, start=START_FROM, end=END_DATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instr.feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Целевая переменная"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Цена закрытия."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_target = instr.c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Переходим к логарифмической доходности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_target = instr.c.transform(transforms={'ratios' : {}, 'ln' : {}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotHelpers.plot_transformed_timeseries_unit(instr,\n",
    "                                             transformed_target,\n",
    "                                             'Daily close price, USD', 'Daily log return')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Трансформация признаков\n",
    "\n",
    "Из признаков выбираем только цену закрытия. Временной ряд цен преобразуется к ряду логарифмических доходностей (что также позволяет убрать нестационарность)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_feature_selector():\n",
    "    price_transformer = lambda: {'ratios': {}, 'ln': {}}\n",
    "    diff_transformer = lambda o: {'diffs': {'order': o}}\n",
    "    identity_transformer = lambda: {}\n",
    "    feature_transformations = {\n",
    "        'c': price_transformer(),\n",
    "    }\n",
    "    return feature_transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instr_transformed = instr.select_transform(make_feature_selector())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_target = instr_transformed.c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучающая, валидационная и тестовая выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instr_train, instr_val_test = instr_transformed.train_test_split(VAL_SPLIT, window_size=WINDOW_SIZE,\n",
    "                                                                 scaler=StandardScaler)\n",
    "#                                                                  scaler=MinMaxScaler,\n",
    "#                                                                  scaler_kwargs={'feature_range': (-1, 1)})\n",
    "\n",
    "instr_val, instr_test = instr_val_test.train_test_split(TEST_SPLIT, window_size=WINDOW_SIZE, scaler=None)\n",
    "\n",
    "len(instr_train), len(instr_val), len(instr_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Признаки - скользящие окна"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mwf = MovingWindowFeatures.create(instr_train.c, [instr_train], instr_train.feature_names, window_size=WINDOW_SIZE)\n",
    "val_mwf = MovingWindowFeatures.create(instr_val.c, [instr_val], instr_val.feature_names, window_size=WINDOW_SIZE)\n",
    "test_mwf = MovingWindowFeatures.create(instr_test.c, [instr_test], instr_test.feature_names, window_size=WINDOW_SIZE)\n",
    "\n",
    "len(instr_train), len(train_mwf), train_mwf.features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка, что скользящие окна соответствуют исходным данным.\n",
    "\n",
    "Возьмём произвольный признак и произвольное окно (строка #**41**). Проверим, что данные в точности совпадают:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_data(md, mwf, row):\n",
    "    col = np.random.randint(len(mwf.feature_names))\n",
    "    feature = mwf.feature_names[col]\n",
    "    check = (getattr(md, feature).data[row:row + mwf.window_size] == mwf.features[row, :, col]).all()\n",
    "    assert check\n",
    "    return feature, check\n",
    "\n",
    "check_data(instr_train, train_mwf, 41)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Модели*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель с двумя 1D свёрточными слоями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_conv1d_layers(input_shape, filters=(16, 8), kernel_size=5, pool_size=2):\n",
    "    # формат входа: наша матрица (окно; признак)\n",
    "    inp = Input(input_shape, name='input')\n",
    "\n",
    "    # стекаем два уровня Conv1D\n",
    "    conv1d = Convolution1D(filters=filters[0],\n",
    "                           kernel_size=kernel_size,\n",
    "                           padding='same',\n",
    "                           bias_initializer='he_uniform',\n",
    "                           bias_regularizer=L1L2(0.01, 0.02),\n",
    "                           kernel_regularizer=L1L2(0.01, 0.02)\n",
    "                          )(inp)\n",
    "    conv1d = BatchNormalization()(conv1d)\n",
    "    conv1d = LeakyReLU()(conv1d)\n",
    "    conv1d = Dropout(0.25)(conv1d)\n",
    "\n",
    "    conv1d = Convolution1D(filters=filters[1],\n",
    "                           kernel_size=kernel_size,\n",
    "                           padding='same',\n",
    "                           bias_initializer='he_uniform',\n",
    "                           bias_regularizer=L1L2(0.01, 0.02),\n",
    "                           kernel_regularizer=L1L2(0.01, 0.02)\n",
    "                          )(conv1d)\n",
    "    conv1d = BatchNormalization()(conv1d)\n",
    "    conv1d = LeakyReLU()(conv1d)\n",
    "    conv1d = Dropout(0.25)(conv1d)\n",
    "    \n",
    "    conv1d = MaxPooling1D(pool_size=pool_size)(conv1d)\n",
    "    \n",
    "    conv1d = Flatten()(conv1d)\n",
    "    \n",
    "    return inp, conv1d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Пути сохранения моделей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path_root = 'models'\n",
    "model_type_name = 'conv1d_univar'\n",
    "\n",
    "def make_model_save_dir(path_root, type_name, class_name):\n",
    "    save_dir = os.path.join(path_root, type_name, class_name)\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    return save_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Общие коллбэки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# уменьшение learning rate в случае, если loss не изменяется\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.00001, verbose=1)\n",
    "\n",
    "# уменьшение learning rate в 2 раза каждую 5-ю эпоху\n",
    "def lr_decay(e, lr):\n",
    "    return lr * (1 - 0.5 * (0 == (e + 1) % 5))\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(schedule=lr_decay, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача регрессии\n",
    "\n",
    "Непосредственное прогнозирование цены следующего периода."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_regr_gen = RegressionGenerator.create(train_mwf, batch_size=BATCH_SIZE)\n",
    "val_regr_gen = RegressionGenerator.create(val_mwf, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_regr_gen = RegressionGenerator.create(test_mwf, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следующие числа соответствуют значению параметра `steps_per_epoch` метода [`fit_generator`](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit_generator \"tf.keras.layers.SimpleRNN &nbsp;|&nbsp; TensorFlow Core r2.0\") - то есть это число батчей, которые генератор выдаст за одну эпоху обучения (если класс генератора поддерживает метод `len()`, то данный параметр можно не указывать)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(train_regr_gen), len(val_regr_gen), len(test_regr_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Один сэмпл данных представляет собой матрицу размером *(длина окна; число признаков)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_regr_gen.input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель для задачи регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class_name = 'regression'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_regression_model(input_shape):\n",
    "    inp, conv1d = build_conv1d_layers(input_shape, filters=(32, 16))\n",
    "\n",
    "    regr = Dense(32)(conv1d)\n",
    "    regr = BatchNormalization()(regr)\n",
    "    regr = LeakyReLU()(regr)\n",
    "    regr = Dropout(0.25)(regr)\n",
    "    regr = Dense(1, activation='linear', name='regr')(regr)\n",
    "\n",
    "    return Model(inputs=[inp], outputs=[regr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "univariate_regression_conv1d = build_regression_model(train_regr_gen.input_shape)\n",
    "\n",
    "model_save_dir = make_model_save_dir(model_path_root, model_type_name, model_class_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Оптимизатор:\n",
    "[`Nadam`](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Nadam) (*Adam with Nestrov momentum*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Nadam(lr=0.001, clipnorm=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Дополнительные коллбэки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint(monitor='val_loss', verbose=1, save_best_only=True,\n",
    "                               filepath=os.path.join(model_save_dir, '{epoch:02d}.hdf5'))\n",
    "\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=5, min_delta=0.001, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Функция потерь:\n",
    "\n",
    "В качестве функции потерь будем использовать [MSE](https://www.tensorflow.org/api_docs/python/tf/keras/losses/MSE) (чтобы штрафовать за большие отклонения). Xотя хорошая функция потерь в контексте темы данной задачи - это [вопрос сложный](https://github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/blob/master/Chapter5_LossFunctions/Ch5_LossFunctions_PyMC3.ipynb). В частности, здесь нам, очевидно, помимо абсолютного значения отклонения также важен его знак."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "univariate_regression_conv1d.compile(optimizer=optimizer,\n",
    "                                   loss={'regr': 'mse'},\n",
    "                                   metrics={'regr': 'mae'})\n",
    "\n",
    "univariate_regression_conv1d.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучение:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_history = utils.train_model(univariate_regression_conv1d,\n",
    "                                 model_save_dir, train_regr_gen, val_regr_gen,\n",
    "                                 callbacks=[reduce_lr, lr_scheduler, checkpointer, earlyStopping],\n",
    "                                 force_train=FORCE_TRAIN, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_regr_history(hist):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    plotHelpers.plot_train_history(ax[0], hist, 'MSE', 'loss', 'val_loss')\n",
    "    plotHelpers.plot_train_history(ax[1], hist, 'MAE', 'mae', 'val_mae')\n",
    "    \n",
    "plot_regr_history(regr_history);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Прогноз задачи регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загружаем последнюю эпоху с минимальным лоссом\n",
    "univariate_regression_conv1d.load_weights(sorted(glob.glob(os.path.join(model_save_dir,'*.hdf5')))[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### На тесте:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_log_ret_test = univariate_regression_conv1d.predict_generator(test_regr_gen, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plotHelpers.plot_regr_predictions(orig_target, instr_test, pred_log_ret_test, figsize=(16, 10), datetime_unit='D')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача классификации\n",
    "\n",
    "Прогнозируем направление изменения цены по сравнению с предыдущим периодом (**0** - снижение, **1** - рост)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class_name = 'classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clf_gen = ClassificationGenerator.create(train_mwf, batch_size=BATCH_SIZE)\n",
    "val_clf_gen = ClassificationGenerator.create(val_mwf, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_clf_gen = ClassificationGenerator.create(test_mwf, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classification_model(input_shape):\n",
    "    inp, conv1d = build_conv1d_layers(input_shape, filters=(32, 16))\n",
    "\n",
    "    clf = Dense(32)(conv1d)\n",
    "    clf = BatchNormalization()(clf)\n",
    "    clf = LeakyReLU()(clf)\n",
    "    clf = Dropout(0.25)(clf)\n",
    "    clf = Dense(1, activation='sigmoid', name='clf')(clf)\n",
    "\n",
    "    return Model(inputs=[inp], outputs=[clf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "univariate_classification_conv1d = build_classification_model(test_clf_gen.input_shape)\n",
    "\n",
    "model_save_dir = make_model_save_dir(model_path_root, model_type_name, model_class_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Оптимизатор:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Nadam(lr=0.001, clipnorm=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Функция потерь:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "univariate_classification_conv1d.compile(optimizer=optimizer,\n",
    "                                         loss={'clf': 'binary_crossentropy'},\n",
    "                                         metrics={'clf': 'accuracy'})\n",
    "\n",
    "univariate_classification_conv1d.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Дополнительные коллбэки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint(monitor='val_loss', verbose=1, save_best_only=True,\n",
    "                               filepath=os.path.join(model_save_dir, '{epoch:02d}.hdf5'))\n",
    "\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=5, min_delta=0.001, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучение:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_history = utils.train_model(univariate_classification_conv1d,\n",
    "                                model_save_dir, train_clf_gen, val_clf_gen,\n",
    "                                callbacks=[reduce_lr, lr_scheduler, checkpointer, earlyStopping],\n",
    "                                force_train=FORCE_TRAIN, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clf_history(hist):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    plotHelpers.plot_train_history(ax[0], hist, 'Loss', 'loss', 'val_loss')\n",
    "    plotHelpers.plot_train_history(ax[1], hist, 'Accuracy', 'accuracy', 'val_accuracy')\n",
    "    \n",
    "plot_clf_history(clf_history);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Прогноз задачи классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загружаем последнюю эпоху с минимальным лоссом\n",
    "univariate_classification_conv1d.load_weights(sorted(glob.glob(os.path.join(model_save_dir,'*.hdf5')))[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_direction_proba = univariate_classification_conv1d.predict_generator(test_clf_gen, verbose=1)\n",
    "\n",
    "true_direction = test_clf_gen.get_target_direction(test_mwf.target[-len(pred_direction_proba):])\n",
    "\n",
    "predicted_direction = (np.mean(pred_direction_proba) < pred_direction_proba).astype(np.int)\n",
    "\n",
    "np.mean(pred_direction_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(true_direction, return_counts=True), \\\n",
    "np.unique(predicted_direction, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(pred_direction_proba, bins=20)\n",
    "plt.axvline(np.mean(pred_direction_proba), c='r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(true_direction, predicted_direction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(true_direction, predicted_direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotHelpers.show_confusion_matrix(true_direction, predicted_direction, ['down', 'up'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotHelpers.plot_roc_pr_curves(true_direction, pred_direction_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Многозадачная модель: одновременно регрессия и классификация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class_name = 'multitask'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_multi_gen = MultitaskGenerator.create(train_mwf, batch_size=BATCH_SIZE)\n",
    "val_multi_gen = MultitaskGenerator.create(val_mwf, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_multi_gen = MultitaskGenerator.create(test_mwf, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_multitask_model(input_shape):\n",
    "    inp, conv1d = build_conv1d_layers(input_shape, filters=(32, 16))\n",
    "\n",
    "    # первый выход: задача регрссии\n",
    "    regr = Dense(32)(conv1d)\n",
    "    regr = BatchNormalization()(regr)\n",
    "    regr = LeakyReLU()(regr)\n",
    "    regr = Dropout(0.25)(regr)\n",
    "    regr = Dense(1, activation='linear', name='regr')(regr)\n",
    "\n",
    "    # второй выход: задача классификации\n",
    "    clf = Dense(32)(conv1d)\n",
    "    clf = BatchNormalization()(clf)\n",
    "    clf = LeakyReLU()(clf)\n",
    "    clf = Dropout(0.25)(clf)\n",
    "    clf = Dense(1, activation='sigmoid', name='clf')(clf)\n",
    "    \n",
    "    return Model(inputs=[inp], outputs=[regr, clf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "univariate_multitask_conv1d = build_multitask_model(train_multi_gen.input_shape)\n",
    "\n",
    "model_save_dir = make_model_save_dir(model_path_root, model_type_name, model_class_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Оптимизатор:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Nadam(lr=0.001, clipnorm=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Функция потерь:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "univariate_multitask_conv1d.compile(optimizer=optimizer,\n",
    "                                    loss={'regr': 'mse', 'clf': 'binary_crossentropy'},\n",
    "                                    loss_weights={'regr': 1., 'clf': 1.},\n",
    "                                    metrics={'regr': 'mae', 'clf' : 'accuracy'})\n",
    "\n",
    "univariate_multitask_conv1d.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Дополнительные коллбэки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint(monitor='val_loss', verbose=1, save_best_only=True,\n",
    "                               filepath=os.path.join(model_save_dir, '{epoch:02d}.hdf5'))\n",
    "\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=5, min_delta=0.001, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучение:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multitask_history = utils.train_model(univariate_multitask_conv1d,\n",
    "                                      model_save_dir, train_multi_gen, val_multi_gen,\n",
    "                                      callbacks=[reduce_lr, lr_scheduler, checkpointer, earlyStopping],\n",
    "                                      force_train=FORCE_TRAIN, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_multitask_history(hist):\n",
    "    fig, ax = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    plotHelpers.plot_train_history(ax[0, 0], hist, 'Total loss', 'loss', 'val_loss')\n",
    "    plotHelpers.plot_train_history(ax[0, 1], hist, 'Accuracy', 'clf_accuracy', 'val_clf_accuracy')\n",
    "    plotHelpers.plot_train_history(ax[1, 0], hist, 'MSE', 'regr_loss', 'val_regr_loss')\n",
    "    plotHelpers.plot_train_history(ax[1, 1], hist, 'MAE', 'regr_mae', 'val_regr_mae')\n",
    "    \n",
    "plot_multitask_history(multitask_history);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Прогноз"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загружаем последнюю эпоху с минимальным лоссом\n",
    "univariate_multitask_conv1d.load_weights(sorted(glob.glob(os.path.join(model_save_dir,'*.hdf5')))[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### На тесте:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_log_ret, pred_direction_proba = univariate_multitask_conv1d.predict_generator(test_multi_gen, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "np.column_stack([pred_log_ret, pred_direction_proba])[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Прогноз задачи регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plotHelpers.plot_regr_predictions(orig_target, instr_test, pred_log_ret, figsize=(16, 10), datetime_unit='D')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Прогноз задачи классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_direction = test_clf_gen.get_target_direction(test_mwf.target[-len(pred_direction_proba):])\n",
    "\n",
    "predicted_direction = (np.mean(pred_direction_proba) < pred_direction_proba).astype(np.int)\n",
    "\n",
    "np.mean(pred_direction_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_direction = test_multi_gen.get_target_direction(test_mwf.target[-len(pred_direction_proba):])\n",
    "\n",
    "predicted_direction = (np.mean(pred_direction_proba) < pred_direction_proba).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(true_direction, return_counts=True), \\\n",
    "np.unique(predicted_direction, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(pred_direction_proba, bins=20)\n",
    "plt.axvline(np.mean(pred_direction_proba), c='r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(true_direction, predicted_direction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(true_direction, predicted_direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotHelpers.show_confusion_matrix(true_direction, predicted_direction, ['down', 'up'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotHelpers.plot_roc_pr_curves(true_direction, pred_direction_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выводы\n",
    "\n",
    "1.  Модель с 1D свёртками обучается гораздо быстрее модели LSTM\n",
    "2.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HSE-ML",
   "language": "python",
   "name": "hse-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
